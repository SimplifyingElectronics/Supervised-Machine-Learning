{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDCxREt1lVuy7WcVRHfTtc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimplifyingElectronics/Supervised-Machine-Learning/blob/main/2_C1_W2_Lab03_Feature_Scaling_and_Learning_Rate_Soln_GD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional Lab: Feature scaling and Learning Rate (Multi-variable)"
      ],
      "metadata": {
        "id": "Hk3xVVtmtEx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goals\n",
        "In this lab you will:\n",
        "- Utilize  the multiple variables routines developed in the previous lab\n",
        "- run Gradient Descent on a data set with multiple features\n",
        "- explore the impact of the *learning rate alpha* on gradient descent\n",
        "- improve performance of gradient descent by *feature scaling* using z-score normalization"
      ],
      "metadata": {
        "id": "Os1JIKSzqIRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools\n",
        "You will utilize the functions developed in the last lab as well as matplotlib and NumPy."
      ],
      "metadata": {
        "id": "Z37BvkoZqRoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone 'https://github.com/SimplifyingElectronics/Supervised-Machine-Learning.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oZfPx5rtme1",
        "outputId": "9b6fb396-ea12-4ca8-9a40-f35159567d0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Supervised-Machine-Learning'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 35 (delta 16), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (35/35), 34.56 KiB | 2.66 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from lab_utils_multi import  load_house_data, run_gradient_descent\n",
        "# from lab_utils_multi import  norm_plot, plt_equal_scale, plot_cost_i_w\n",
        "# from lab_utils_common import dlc\n",
        "# np.set_printoptions(precision=2)\n",
        "# plt.style.use('./deeplearning.mplstyle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "sLqehX4PqSGF",
        "outputId": "f4d4e4ea-520f-4f46-a779-ccf3d9fc6144"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `git clone ('https://github.com/SimplifyingElectronics/Supervised-Machine-Learning')'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lab_utils_multi'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3305876530.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlab_utils_multi\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mload_house_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_gradient_descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# from lab_utils_multi import  norm_plot, plt_equal_scale, plot_cost_i_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# from lab_utils_common import dlc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lab_utils_multi'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notation\n",
        "\n",
        "|General <br />  Notation  | Description| Python (if applicable) |\n",
        "|: ------------|: ------------------------------------------------------------||\n",
        "| $a$ | scalar, non bold                                                      ||\n",
        "| $\\mathbf{a}$ | vector, bold                                                 ||\n",
        "| $\\mathbf{A}$ | matrix, bold capital                                         ||\n",
        "| **Regression** |         |    |     |\n",
        "|  $\\mathbf{X}$ | training example maxtrix                  | `X_train` |   \n",
        "|  $\\mathbf{y}$  | training example  targets                | `y_train`\n",
        "|  $\\mathbf{x}^{(i)}$, $y^{(i)}$ | $i_{th}$Training Example | `X[i]`, `y[i]`|\n",
        "| m | number of training examples | `m`|\n",
        "| n | number of features in each example | `n`|\n",
        "|  $\\mathbf{w}$  |  parameter: weight,                       | `w`    |\n",
        "|  $b$           |  parameter: bias                                           | `b`    |     \n",
        "| $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ | The result of the model evaluation at  $\\mathbf{x}^{(i)}$ parameterized by $\\mathbf{w},b$: $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+b$  | `f_wb` |\n",
        "|$\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}$| the gradient or partial derivative of cost with respect to a parameter $w_j$ |`dj_dw[j]`|\n",
        "|$\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$| the gradient or partial derivative of cost with respect to a parameter $b$| `dj_db`|"
      ],
      "metadata": {
        "id": "izhfMVr9qZz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Problem Statement\n",
        "\n",
        "As in the previous labs, you will use the motivating example of housing price prediction. The training data set contains many examples with 4 features (size, bedrooms, floors and age) shown in the table below. Note, in this lab, the Size feature is in sqft while earlier labs utilized 1000 sqft.  This data set is larger than the previous lab.\n",
        "\n",
        "We would like to build a linear regression model using these values so we can then predict the price for other houses - say, a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old.\n",
        "\n",
        "##  Dataset:\n",
        "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
        "| ----------------| ------------------- |----------------- |--------------|----------------------- |  \n",
        "| 952             | 2                   | 1                | 65           | 271.5                  |  \n",
        "| 1244            | 3                   | 2                | 64           | 232                    |  \n",
        "| 1947            | 3                   | 2                | 17           | 509.8                  |  \n",
        "| ...             | ...                 | ...              | ...          | ...                    |\n"
      ],
      "metadata": {
        "id": "2Wq7e9vcqdxr"
      }
    }
  ]
}
